# define prune ratios for your network
# 80.98 / 5.27x (column sparsity / weight sparsity)
prune_ratios:
  conv1:
    0.0156
  layer1.0.conv1:
    0.8350
  layer1.0.conv2:
    0.8371
  layer1.0.conv3:
    0.9595
  layer1.1.conv1:
    0.9587
  layer1.1.conv2:
    0.9764
  layer1.1.conv3:
    0.9762
  layer1.2.conv1:
    0.9762
  layer1.2.conv2:
    0.9764
  layer1.2.conv3:
    0.9762
  layer2.0.conv1:
    0.9762
  layer2.0.conv2:
    0.9764
  layer2.0.conv3:
    0.9765
  layer2.1.conv1:
    0.9897
  layer2.1.conv2:
    0.9897
  layer2.1.conv3:
    0.9897
  layer2.2.conv1:
    0.9972
  layer2.2.conv2:
    0.9972
  layer2.2.conv3:
    0.9972
  layer2.3.conv1:
    0.9981
  layer2.3.conv2:
    0.9995
  layer2.3.conv3:
    0.9995
  layer3.0.conv1:
    0.9995
  layer3.0.conv2:
    0.9995
  layer3.0.conv3:
    0.9995
  layer3.1.conv1:
    0.9995
  layer3.1.conv2:
    0.9974
  layer3.1.conv3:
    0.9898
  layer3.2.conv1:
    0.9898
  layer3.2.conv2:
    0.9898
  layer3.2.conv3:
    0.9898
  layer3.3.conv1:
    0.9898
  layer3.3.conv2:
    0.9898
  layer3.3.conv3:
    0.9898
  layer3.4.conv1:
    0.9898
  layer3.4.conv2:
    0.9898
  layer3.4.conv3:
    0.9898
  layer3.5.conv1:
    0.9898
  layer3.5.conv2:
    0.9898
  layer3.5.conv3:
    0.9934
  layer4.0.conv1:
    0.9936
  layer4.0.conv2:
    0.9975
  layer4.0.conv3:
    0.9974
  layer4.1.conv1:
    0.9898
  layer4.1.conv2:
    0.9898
  layer4.1.conv3:
    0.9898
  layer4.2.conv1:
    0.9898
  layer4.2.conv2:
    0.9898
  layer4.2.conv3:
    0.9597